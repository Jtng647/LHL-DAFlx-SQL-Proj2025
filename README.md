# Final-Project-Transforming-and-Analyzing-Data-with-SQL

## Project/Goals
The scope of this project was to show familiarity and proficient ability in working with SQL to transform and analyze data in a database. This was done by going through several challenges involving setting up the database and project environment, cleaning the data, answering predefined questions, developing new and unique questions, and applying QA techniques to the data on hand. All of the above would result in a project portfolio that contains SQL queries and analytical answers to the questions posed.

## Process
### Step 1:
Set up the database in pgAdmin using the provided CSV files to create the working environment in which to demonstrate SQL knowledge.

### Step 2:
Become familiar with the data by looking through the tables, opening the CSVs in Excel to get an idea of the data variants in the columns, and figuiring out the source of this data to understand the context and the nature in which this data was collected.

### Step 3:
Work with the data to answer the predefined questions, making note of any data inconsistencies or problematic values that would need to be cleaned as a whole, and during the problem solving process for the questions.

### Step 4:
Based on the observations and actions taken during the question-answering process, highlight and demonstrate the data cleaning processes that needed to be done to make this data set workable, consistent, and reliable.

### Step 5:
Define new questions that could be asked of this data based on the information now known after answering the predefined questions. Attempt to answer those questions with new queries and ways of manipulating the data. Analyze the results to draw conclusions, and make note of possible pitfalls of the methods applied for Quality Assurance in the next step.

### Step 6:
Question and challenge the conclusions drawn from the answers to the questions. Test the transformed data that was used to support analytical conclusions to ensure validity and Quality Assurance by using counter-queries.

### Step 7:
Consolidate the findings and publish them onto a repository as a project portfolio.

## Results
The data was found to be from an online shopping website, that tracked visits and orders from its customers. It was a collection of website traffic, order statistics, and internal product management. Of particular note, since this was a website, it had clients and site visitors worldwide and so it was a sample of data that spanned a large market. This data could provide patterns, historical trends, and drive potential decisions for this business moving forward.

By analyzing information such as: the Total Transaction Revenue, the countries/cities from which the orders were made, the rankings of such information, and the implications that could be interpreted when they are considered in conjunction with one another; both the predefined questions and the proposed questions could be answered.

## Challenges 
The main challenge that was faced was the sheer amount of data to parse through and consider. Much of which needed to filtered out as they were inconsequential, seemingly or in actuality. Even the data that was useful had thousands of entries, which made interpeting analytical conclusions difficult. The data itself was also largely inconsistent and had many outliers. However, this is where the transformation of data and SQL techniques were invaluable in processing the information.

## Future Goals
If there was more time, it would be quite valuable to truly understand what some of the data and columns represented. Most of the headers in the provided data were not immediately intuitave, and a lot of information was not used to prevent unwanted information from factoring into the results and skewing the data. However, if understood and applied properly, it may actually reinforce or support the analytical conclusions that were drawn.
